{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Basic_multilayer_perceptron-final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asattiraju13/datahackathon/blob/main/basic_multilayer_perceptron_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JELGBE1SLP79",
        "outputId": "50b778a2-726e-4f48-91d3-625b657428a5"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import class_weight\n",
        "# import tensorflow as tf\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Flatten, Dense, Dropout, Activation\n",
        "from keras.utils import to_categorical\n",
        "from keras import optimizers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iapt6RZfL7Ot"
      },
      "source": [
        "import os\n",
        "\n",
        "data = \"C:/Users/antho/Downloads/scBALF-COVID-19/covid-selected-data.csv\"\n",
        "label_file = \"C:/Users/antho/Downloads/scBALF-COVID-19/covid-selected-data-labels.csv\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IPo9oLTL9Z3"
      },
      "source": [
        "import io\n",
        "df = pd.read_csv(data)\n",
        "labels = pd.read_csv(label_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTX2f8VYMBVF"
      },
      "source": [
        "data = pd.merge(df,labels,on='Unnamed: 0')\n",
        "data['type'] = data['type'].map({'Normal':0,'Mild':1,'Severe':2})\n",
        "df = []\n",
        "\n",
        "X = data.drop('type',axis=1).values  # Apply feature processing, reduction, imbalancing later on / instead of stratified split?\n",
        "X = X[:,1:]\n",
        "y = data['type'].values\n",
        "genes = data.columns[1:2000]\n",
        "data = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGk7ano2MFi4",
        "scrolled": true,
        "outputId": "9204013c-fe34-4262-c073-e45d653465ab"
      },
      "source": [
        "sss = StratifiedShuffleSplit(n_splits=5,test_size=0.2,train_size=0.8,random_state=0) # n_splits should equal 5\n",
        "NEpochs = 50\n",
        "\n",
        "y_pred_all = []; y_all = [];\n",
        "\n",
        "# Split data into Training + Validation and Test Groups\n",
        "for train_val_index, test_index in sss.split(X,y):\n",
        "    X_train_val = X[train_val_index]\n",
        "    y_train_val = y[train_val_index]\n",
        "    \n",
        "    X_test = X[test_index]\n",
        "    y_test = y[test_index]\n",
        "    \n",
        "    # Split Train/Val Data into Training and Validation Groups\n",
        "    sss2 = StratifiedShuffleSplit(n_splits=1,test_size=0.25,train_size=0.75,random_state=0)\n",
        "    for train_index, val_index in sss2.split(X_train_val,y_train_val):\n",
        "        X_train = X_train_val[train_index]\n",
        "        y_train = y_train_val[train_index]\n",
        "        \n",
        "        X_val = X_train_val[val_index]\n",
        "        y_val = y_train_val[val_index]\n",
        "        \n",
        "        X_train_val = []\n",
        "        y_train_val = []\n",
        "        \n",
        "        #%% Create Weights for Model Classes\n",
        "        values, counts = np.unique(y_train, return_counts=True)\n",
        "        weights = class_weight.compute_class_weight('balanced', np.unique(y_train), np.squeeze(y_train))\n",
        "        class_weights = dict(zip(values, weights))\n",
        "        \n",
        "        # TRAIN AND TEST MODEL HERE\n",
        "        \n",
        "        model = Classifier((1999,1))\n",
        "        history = model.fit(np.expand_dims(X_train,axis=2), to_categorical(y_train), epochs=NEpochs, batch_size=124,shuffle=True,validation_data=(np.expand_dims(X_val,axis=2), to_categorical(np.array(y_val))),class_weight=class_weights) #change trainvalidx when using normalization\n",
        "        \n",
        "        y_pred_all.append(model.predict(np.expand_dims(X_test,axis=2)))\n",
        "        y_all.append(y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\antho\\Anaconda3\\envs\\DeepEnv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From C:\\Users\\antho\\Anaconda3\\envs\\DeepEnv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From C:\\Users\\antho\\Anaconda3\\envs\\DeepEnv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "WARNING:tensorflow:From C:\\Users\\antho\\Anaconda3\\envs\\DeepEnv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From C:\\Users\\antho\\Anaconda3\\envs\\DeepEnv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From C:\\Users\\antho\\Anaconda3\\envs\\DeepEnv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From C:\\Users\\antho\\Anaconda3\\envs\\DeepEnv\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From C:\\Users\\antho\\Anaconda3\\envs\\DeepEnv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From C:\\Users\\antho\\Anaconda3\\envs\\DeepEnv\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From C:\\Users\\antho\\Anaconda3\\envs\\DeepEnv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From C:\\Users\\antho\\Anaconda3\\envs\\DeepEnv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From C:\\Users\\antho\\Anaconda3\\envs\\DeepEnv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 13913 samples, validate on 4638 samples\n",
            "Epoch 1/50\n",
            "WARNING:tensorflow:From C:\\Users\\antho\\Anaconda3\\envs\\DeepEnv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From C:\\Users\\antho\\Anaconda3\\envs\\DeepEnv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From C:\\Users\\antho\\Anaconda3\\envs\\DeepEnv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From C:\\Users\\antho\\Anaconda3\\envs\\DeepEnv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From C:\\Users\\antho\\Anaconda3\\envs\\DeepEnv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "13913/13913 [==============================] - 12s 880us/step - loss: 1.0954 - acc: 0.4199 - val_loss: 0.9885 - val_acc: 0.5580\n",
            "Epoch 2/50\n",
            "13913/13913 [==============================] - 6s 466us/step - loss: 0.9852 - acc: 0.5222 - val_loss: 0.8892 - val_acc: 0.6600\n",
            "Epoch 3/50\n",
            "13913/13913 [==============================] - 7s 469us/step - loss: 0.9049 - acc: 0.6101 - val_loss: 0.8129 - val_acc: 0.7001\n",
            "Epoch 4/50\n",
            "13913/13913 [==============================] - 6s 432us/step - loss: 0.8140 - acc: 0.6554 - val_loss: 0.7200 - val_acc: 0.7398\n",
            "Epoch 5/50\n",
            "13913/13913 [==============================] - 6s 458us/step - loss: 0.7283 - acc: 0.7034 - val_loss: 0.6399 - val_acc: 0.7721\n",
            "Epoch 6/50\n",
            "13913/13913 [==============================] - 6s 445us/step - loss: 0.6531 - acc: 0.7378 - val_loss: 0.5737 - val_acc: 0.7962\n",
            "Epoch 7/50\n",
            "13913/13913 [==============================] - 6s 445us/step - loss: 0.5795 - acc: 0.7661 - val_loss: 0.5418 - val_acc: 0.7943\n",
            "Epoch 8/50\n",
            "13913/13913 [==============================] - 6s 441us/step - loss: 0.5094 - acc: 0.7919 - val_loss: 0.4762 - val_acc: 0.8215\n",
            "Epoch 9/50\n",
            "13913/13913 [==============================] - 8s 545us/step - loss: 0.4656 - acc: 0.8077 - val_loss: 0.4379 - val_acc: 0.8346\n",
            "Epoch 10/50\n",
            "13913/13913 [==============================] - 6s 445us/step - loss: 0.4123 - acc: 0.8294 - val_loss: 0.4134 - val_acc: 0.8480\n",
            "Epoch 11/50\n",
            "13913/13913 [==============================] - 8s 585us/step - loss: 0.3665 - acc: 0.8526 - val_loss: 0.4026 - val_acc: 0.8560\n",
            "Epoch 12/50\n",
            "13913/13913 [==============================] - 9s 634us/step - loss: 0.3410 - acc: 0.8587 - val_loss: 0.3944 - val_acc: 0.8588\n",
            "Epoch 13/50\n",
            "13913/13913 [==============================] - 9s 625us/step - loss: 0.3109 - acc: 0.8764 - val_loss: 0.3856 - val_acc: 0.8674\n",
            "Epoch 14/50\n",
            "13913/13913 [==============================] - 10s 705us/step - loss: 0.2873 - acc: 0.8810 - val_loss: 0.3818 - val_acc: 0.8691\n",
            "Epoch 15/50\n",
            "13913/13913 [==============================] - 7s 490us/step - loss: 0.2590 - acc: 0.8966 - val_loss: 0.3780 - val_acc: 0.8730\n",
            "Epoch 16/50\n",
            "13913/13913 [==============================] - 7s 514us/step - loss: 0.2445 - acc: 0.9022 - val_loss: 0.3749 - val_acc: 0.8769\n",
            "Epoch 17/50\n",
            "13913/13913 [==============================] - 7s 470us/step - loss: 0.2367 - acc: 0.9069 - val_loss: 0.3741 - val_acc: 0.8797\n",
            "Epoch 18/50\n",
            "13913/13913 [==============================] - 6s 445us/step - loss: 0.2200 - acc: 0.9132 - val_loss: 0.3715 - val_acc: 0.8784\n",
            "Epoch 19/50\n",
            "13913/13913 [==============================] - 6s 429us/step - loss: 0.2059 - acc: 0.9176 - val_loss: 0.3973 - val_acc: 0.8827\n",
            "Epoch 20/50\n",
            "13913/13913 [==============================] - 7s 498us/step - loss: 0.2015 - acc: 0.9200 - val_loss: 0.3869 - val_acc: 0.8857\n",
            "Epoch 21/50\n",
            "13913/13913 [==============================] - 6s 453us/step - loss: 0.1977 - acc: 0.9230 - val_loss: 0.3813 - val_acc: 0.8892\n",
            "Epoch 22/50\n",
            "13913/13913 [==============================] - 9s 672us/step - loss: 0.1827 - acc: 0.9311 - val_loss: 0.4010 - val_acc: 0.8881\n",
            "Epoch 23/50\n",
            "13913/13913 [==============================] - 7s 529us/step - loss: 0.1772 - acc: 0.9329 - val_loss: 0.4008 - val_acc: 0.8866\n",
            "Epoch 24/50\n",
            "13913/13913 [==============================] - 9s 669us/step - loss: 0.1621 - acc: 0.9398 - val_loss: 0.3961 - val_acc: 0.8909\n",
            "Epoch 25/50\n",
            "13913/13913 [==============================] - 9s 674us/step - loss: 0.1597 - acc: 0.9419 - val_loss: 0.4361 - val_acc: 0.8892\n",
            "Epoch 26/50\n",
            "13913/13913 [==============================] - 9s 626us/step - loss: 0.1574 - acc: 0.9399 - val_loss: 0.4363 - val_acc: 0.8939\n",
            "Epoch 27/50\n",
            "13913/13913 [==============================] - 6s 450us/step - loss: 0.1561 - acc: 0.9437 - val_loss: 0.4185 - val_acc: 0.8950\n",
            "Epoch 28/50\n",
            "13913/13913 [==============================] - 6s 425us/step - loss: 0.1516 - acc: 0.9445 - val_loss: 0.4480 - val_acc: 0.8887\n",
            "Epoch 29/50\n",
            "13913/13913 [==============================] - 6s 443us/step - loss: 0.1548 - acc: 0.9408 - val_loss: 0.4383 - val_acc: 0.8918\n",
            "Epoch 30/50\n",
            "13913/13913 [==============================] - 6s 424us/step - loss: 0.1428 - acc: 0.9487 - val_loss: 0.4478 - val_acc: 0.8900\n",
            "Epoch 31/50\n",
            "13913/13913 [==============================] - 6s 451us/step - loss: 0.1423 - acc: 0.9488 - val_loss: 0.4505 - val_acc: 0.8896\n",
            "Epoch 32/50\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "13913/13913 [==============================] - 6s 418us/step - loss: 0.1330 - acc: 0.9521 - val_loss: 0.4451 - val_acc: 0.8898\n",
            "Epoch 33/50\n",
            "13913/13913 [==============================] - 6s 454us/step - loss: 0.1326 - acc: 0.9520 - val_loss: 0.4552 - val_acc: 0.8894\n",
            "Epoch 34/50\n",
            "13913/13913 [==============================] - 6s 442us/step - loss: 0.1202 - acc: 0.9564 - val_loss: 0.4780 - val_acc: 0.8885\n",
            "Epoch 35/50\n",
            "13913/13913 [==============================] - 6s 416us/step - loss: 0.1257 - acc: 0.9549 - val_loss: 0.4820 - val_acc: 0.8892\n",
            "Epoch 36/50\n",
            "13913/13913 [==============================] - 6s 439us/step - loss: 0.1215 - acc: 0.9561 - val_loss: 0.4771 - val_acc: 0.8933\n",
            "Epoch 37/50\n",
            "13913/13913 [==============================] - 7s 488us/step - loss: 0.1254 - acc: 0.9539 - val_loss: 0.4838 - val_acc: 0.8909\n",
            "Epoch 38/50\n",
            "13913/13913 [==============================] - 8s 560us/step - loss: 0.1222 - acc: 0.9568 - val_loss: 0.5110 - val_acc: 0.8890\n",
            "Epoch 39/50\n",
            "13913/13913 [==============================] - 8s 579us/step - loss: 0.1122 - acc: 0.9605 - val_loss: 0.4983 - val_acc: 0.8907\n",
            "Epoch 40/50\n",
            "13913/13913 [==============================] - 6s 430us/step - loss: 0.1212 - acc: 0.9577 - val_loss: 0.5011 - val_acc: 0.8883\n",
            "Epoch 41/50\n",
            "13913/13913 [==============================] - 6s 436us/step - loss: 0.1156 - acc: 0.9576 - val_loss: 0.4985 - val_acc: 0.8890\n",
            "Epoch 42/50\n",
            "13913/13913 [==============================] - 7s 519us/step - loss: 0.1063 - acc: 0.9620 - val_loss: 0.5141 - val_acc: 0.8913\n",
            "Epoch 43/50\n",
            "13913/13913 [==============================] - 6s 461us/step - loss: 0.1175 - acc: 0.9589 - val_loss: 0.5093 - val_acc: 0.8903\n",
            "Epoch 44/50\n",
            "13913/13913 [==============================] - 6s 452us/step - loss: 0.1071 - acc: 0.9605 - val_loss: 0.5040 - val_acc: 0.8972\n",
            "Epoch 45/50\n",
            "13913/13913 [==============================] - 6s 451us/step - loss: 0.1050 - acc: 0.9634 - val_loss: 0.5078 - val_acc: 0.8944\n",
            "Epoch 46/50\n",
            "13913/13913 [==============================] - 6s 427us/step - loss: 0.1058 - acc: 0.9620 - val_loss: 0.5567 - val_acc: 0.8879\n",
            "Epoch 47/50\n",
            "13913/13913 [==============================] - 6s 462us/step - loss: 0.1144 - acc: 0.9597 - val_loss: 0.5096 - val_acc: 0.8944\n",
            "Epoch 48/50\n",
            "13913/13913 [==============================] - 7s 534us/step - loss: 0.1044 - acc: 0.9623 - val_loss: 0.5291 - val_acc: 0.8937\n",
            "Epoch 49/50\n",
            "13913/13913 [==============================] - 7s 505us/step - loss: 0.1071 - acc: 0.9609 - val_loss: 0.5135 - val_acc: 0.8967\n",
            "Epoch 50/50\n",
            "13913/13913 [==============================] - 6s 463us/step - loss: 0.1033 - acc: 0.9633 - val_loss: 0.5067 - val_acc: 0.8972\n",
            "Train on 13913 samples, validate on 4638 samples\n",
            "Epoch 1/50\n",
            "13913/13913 [==============================] - 6s 458us/step - loss: 1.1598 - acc: 0.3975 - val_loss: 1.0230 - val_acc: 0.4877\n",
            "Epoch 2/50\n",
            "13913/13913 [==============================] - 6s 459us/step - loss: 1.0310 - acc: 0.4520 - val_loss: 0.9392 - val_acc: 0.6016\n",
            "Epoch 3/50\n",
            "13913/13913 [==============================] - 6s 456us/step - loss: 0.9570 - acc: 0.5296 - val_loss: 0.8559 - val_acc: 0.6406\n",
            "Epoch 4/50\n",
            "13913/13913 [==============================] - 6s 442us/step - loss: 0.8780 - acc: 0.5970 - val_loss: 0.7492 - val_acc: 0.7100\n",
            "Epoch 5/50\n",
            "13913/13913 [==============================] - 6s 461us/step - loss: 0.7925 - acc: 0.6460 - val_loss: 0.6887 - val_acc: 0.7247\n",
            "Epoch 6/50\n",
            "13913/13913 [==============================] - 6s 436us/step - loss: 0.7120 - acc: 0.7023 - val_loss: 0.6141 - val_acc: 0.7574\n",
            "Epoch 7/50\n",
            "13913/13913 [==============================] - 7s 487us/step - loss: 0.6424 - acc: 0.7371 - val_loss: 0.5643 - val_acc: 0.7844\n",
            "Epoch 8/50\n",
            "13913/13913 [==============================] - 8s 590us/step - loss: 0.5687 - acc: 0.7671 - val_loss: 0.5168 - val_acc: 0.8014\n",
            "Epoch 9/50\n",
            "13913/13913 [==============================] - 6s 451us/step - loss: 0.5149 - acc: 0.7931 - val_loss: 0.4622 - val_acc: 0.8251\n",
            "Epoch 10/50\n",
            "13913/13913 [==============================] - 6s 428us/step - loss: 0.4610 - acc: 0.8119 - val_loss: 0.4316 - val_acc: 0.8428\n",
            "Epoch 11/50\n",
            "13913/13913 [==============================] - 6s 431us/step - loss: 0.4089 - acc: 0.8363 - val_loss: 0.4081 - val_acc: 0.8547\n",
            "Epoch 12/50\n",
            "13913/13913 [==============================] - 6s 441us/step - loss: 0.3708 - acc: 0.8529 - val_loss: 0.3994 - val_acc: 0.8555\n",
            "Epoch 13/50\n",
            "13913/13913 [==============================] - 6s 448us/step - loss: 0.3539 - acc: 0.8603 - val_loss: 0.3882 - val_acc: 0.8700\n",
            "Epoch 14/50\n",
            "13913/13913 [==============================] - 6s 437us/step - loss: 0.3255 - acc: 0.8717 - val_loss: 0.3803 - val_acc: 0.8661\n",
            "Epoch 15/50\n",
            "13913/13913 [==============================] - 8s 600us/step - loss: 0.2959 - acc: 0.8832 - val_loss: 0.3829 - val_acc: 0.8732\n",
            "Epoch 16/50\n",
            "13913/13913 [==============================] - 8s 568us/step - loss: 0.2833 - acc: 0.8908 - val_loss: 0.3970 - val_acc: 0.8773\n",
            "Epoch 17/50\n",
            "13913/13913 [==============================] - 6s 455us/step - loss: 0.2611 - acc: 0.9007 - val_loss: 0.3873 - val_acc: 0.8762\n",
            "Epoch 18/50\n",
            "13913/13913 [==============================] - 6s 435us/step - loss: 0.2480 - acc: 0.9046 - val_loss: 0.3914 - val_acc: 0.8773\n",
            "Epoch 19/50\n",
            "13913/13913 [==============================] - 7s 538us/step - loss: 0.2238 - acc: 0.9139 - val_loss: 0.4099 - val_acc: 0.8821\n",
            "Epoch 20/50\n",
            "13913/13913 [==============================] - 13s 931us/step - loss: 0.2177 - acc: 0.9203 - val_loss: 0.4076 - val_acc: 0.8795\n",
            "Epoch 21/50\n",
            "13913/13913 [==============================] - 8s 584us/step - loss: 0.2114 - acc: 0.9215 - val_loss: 0.4223 - val_acc: 0.8834\n",
            "Epoch 22/50\n",
            "13913/13913 [==============================] - 6s 443us/step - loss: 0.2045 - acc: 0.9234 - val_loss: 0.4166 - val_acc: 0.8846\n",
            "Epoch 23/50\n",
            "13913/13913 [==============================] - 8s 593us/step - loss: 0.1966 - acc: 0.9258 - val_loss: 0.4143 - val_acc: 0.8866\n",
            "Epoch 24/50\n",
            "13913/13913 [==============================] - 7s 513us/step - loss: 0.1917 - acc: 0.9269 - val_loss: 0.4301 - val_acc: 0.8844\n",
            "Epoch 25/50\n",
            "13913/13913 [==============================] - 7s 528us/step - loss: 0.1910 - acc: 0.9308 - val_loss: 0.4136 - val_acc: 0.8892\n",
            "Epoch 26/50\n",
            "13913/13913 [==============================] - 6s 440us/step - loss: 0.1847 - acc: 0.9324 - val_loss: 0.4409 - val_acc: 0.8862\n",
            "Epoch 27/50\n",
            "13913/13913 [==============================] - 6s 443us/step - loss: 0.1757 - acc: 0.9348 - val_loss: 0.4151 - val_acc: 0.8924\n",
            "Epoch 28/50\n",
            "13913/13913 [==============================] - 8s 544us/step - loss: 0.1623 - acc: 0.9404 - val_loss: 0.4731 - val_acc: 0.8859\n",
            "Epoch 29/50\n",
            "13913/13913 [==============================] - 6s 450us/step - loss: 0.1687 - acc: 0.9392 - val_loss: 0.4739 - val_acc: 0.8879\n",
            "Epoch 30/50\n",
            "13913/13913 [==============================] - 7s 523us/step - loss: 0.1542 - acc: 0.9427 - val_loss: 0.4815 - val_acc: 0.8870\n",
            "Epoch 31/50\n",
            "13913/13913 [==============================] - 6s 442us/step - loss: 0.1592 - acc: 0.9405 - val_loss: 0.4676 - val_acc: 0.8909\n",
            "Epoch 32/50\n",
            "13913/13913 [==============================] - 6s 461us/step - loss: 0.1466 - acc: 0.9486 - val_loss: 0.5062 - val_acc: 0.8866\n",
            "Epoch 33/50\n",
            "13913/13913 [==============================] - 6s 450us/step - loss: 0.1462 - acc: 0.9476 - val_loss: 0.4823 - val_acc: 0.8879\n",
            "Epoch 34/50\n",
            "13913/13913 [==============================] - 7s 497us/step - loss: 0.1344 - acc: 0.9508 - val_loss: 0.5338 - val_acc: 0.8896\n",
            "Epoch 35/50\n",
            "13913/13913 [==============================] - 7s 525us/step - loss: 0.1417 - acc: 0.9475 - val_loss: 0.4809 - val_acc: 0.8905\n",
            "Epoch 36/50\n",
            "13913/13913 [==============================] - 12s 827us/step - loss: 0.1444 - acc: 0.9478 - val_loss: 0.4594 - val_acc: 0.8905\n",
            "Epoch 37/50\n",
            "13913/13913 [==============================] - 10s 695us/step - loss: 0.1358 - acc: 0.9498 - val_loss: 0.5116 - val_acc: 0.8846\n",
            "Epoch 38/50\n",
            "13913/13913 [==============================] - 8s 574us/step - loss: 0.1377 - acc: 0.9495 - val_loss: 0.5083 - val_acc: 0.8944\n",
            "Epoch 39/50\n",
            "13913/13913 [==============================] - 6s 452us/step - loss: 0.1323 - acc: 0.9526 - val_loss: 0.5233 - val_acc: 0.8877\n",
            "Epoch 40/50\n",
            "13913/13913 [==============================] - 9s 663us/step - loss: 0.1386 - acc: 0.9492 - val_loss: 0.5568 - val_acc: 0.8883\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 41/50\n",
            "13913/13913 [==============================] - 6s 441us/step - loss: 0.1261 - acc: 0.9548 - val_loss: 0.5144 - val_acc: 0.8935\n",
            "Epoch 42/50\n",
            "13913/13913 [==============================] - 6s 447us/step - loss: 0.1315 - acc: 0.9545 - val_loss: 0.5625 - val_acc: 0.8890\n",
            "Epoch 43/50\n",
            "13913/13913 [==============================] - 6s 433us/step - loss: 0.1231 - acc: 0.9546 - val_loss: 0.5637 - val_acc: 0.8885\n",
            "Epoch 44/50\n",
            "13913/13913 [==============================] - 6s 435us/step - loss: 0.1220 - acc: 0.9553 - val_loss: 0.5386 - val_acc: 0.8924\n",
            "Epoch 45/50\n",
            "13913/13913 [==============================] - 7s 468us/step - loss: 0.1241 - acc: 0.9569 - val_loss: 0.5469 - val_acc: 0.8935\n",
            "Epoch 46/50\n",
            "13913/13913 [==============================] - 6s 450us/step - loss: 0.1162 - acc: 0.9583 - val_loss: 0.5839 - val_acc: 0.8862\n",
            "Epoch 47/50\n",
            "13913/13913 [==============================] - 7s 481us/step - loss: 0.1141 - acc: 0.9597 - val_loss: 0.5562 - val_acc: 0.8909\n",
            "Epoch 48/50\n",
            "13913/13913 [==============================] - 9s 670us/step - loss: 0.1184 - acc: 0.9599 - val_loss: 0.5874 - val_acc: 0.8900\n",
            "Epoch 49/50\n",
            "13913/13913 [==============================] - 6s 455us/step - loss: 0.1125 - acc: 0.9599 - val_loss: 0.5830 - val_acc: 0.8907\n",
            "Epoch 50/50\n",
            "13913/13913 [==============================] - 6s 454us/step - loss: 0.1213 - acc: 0.9564 - val_loss: 0.6055 - val_acc: 0.8887\n",
            "Train on 13913 samples, validate on 4638 samples\n",
            "Epoch 1/50\n",
            "13913/13913 [==============================] - 7s 508us/step - loss: 1.1364 - acc: 0.4393 - val_loss: 0.9970 - val_acc: 0.5936\n",
            "Epoch 2/50\n",
            "13913/13913 [==============================] - 8s 560us/step - loss: 1.0239 - acc: 0.5378 - val_loss: 0.9250 - val_acc: 0.6632.0221 - ac\n",
            "Epoch 3/50\n",
            "13913/13913 [==============================] - 8s 572us/step - loss: 0.9476 - acc: 0.5975 - val_loss: 0.8249 - val_acc: 0.7165\n",
            "Epoch 4/50\n",
            "13913/13913 [==============================] - 9s 669us/step - loss: 0.8712 - acc: 0.6349 - val_loss: 0.7426 - val_acc: 0.7387\n",
            "Epoch 5/50\n",
            "13913/13913 [==============================] - 7s 474us/step - loss: 0.7909 - acc: 0.6709 - val_loss: 0.6516 - val_acc: 0.7702\n",
            "Epoch 6/50\n",
            "13913/13913 [==============================] - 7s 506us/step - loss: 0.7144 - acc: 0.7043 - val_loss: 0.6050 - val_acc: 0.7820\n",
            "Epoch 7/50\n",
            "13913/13913 [==============================] - 6s 426us/step - loss: 0.6443 - acc: 0.7305 - val_loss: 0.5446 - val_acc: 0.8042\n",
            "Epoch 8/50\n",
            "13913/13913 [==============================] - 6s 439us/step - loss: 0.5815 - acc: 0.7558 - val_loss: 0.5121 - val_acc: 0.8085\n",
            "Epoch 9/50\n",
            "13913/13913 [==============================] - 6s 445us/step - loss: 0.5148 - acc: 0.7863 - val_loss: 0.4628 - val_acc: 0.8299\n",
            "Epoch 10/50\n",
            "13913/13913 [==============================] - 6s 461us/step - loss: 0.4639 - acc: 0.8049 - val_loss: 0.4413 - val_acc: 0.8331\n",
            "Epoch 11/50\n",
            "13913/13913 [==============================] - 7s 489us/step - loss: 0.4134 - acc: 0.8270 - val_loss: 0.4147 - val_acc: 0.8489\n",
            "Epoch 12/50\n",
            "13913/13913 [==============================] - 6s 430us/step - loss: 0.3858 - acc: 0.8407 - val_loss: 0.4050 - val_acc: 0.8586\n",
            "Epoch 13/50\n",
            "13913/13913 [==============================] - 6s 445us/step - loss: 0.3494 - acc: 0.8554 - val_loss: 0.3971 - val_acc: 0.8560\n",
            "Epoch 14/50\n",
            "13913/13913 [==============================] - 7s 472us/step - loss: 0.3071 - acc: 0.8740 - val_loss: 0.3880 - val_acc: 0.8672\n",
            "Epoch 15/50\n",
            "13913/13913 [==============================] - 7s 478us/step - loss: 0.2880 - acc: 0.8842 - val_loss: 0.3837 - val_acc: 0.8687\n",
            "Epoch 16/50\n",
            "13913/13913 [==============================] - 6s 445us/step - loss: 0.2785 - acc: 0.8839 - val_loss: 0.3815 - val_acc: 0.8756\n",
            "Epoch 17/50\n",
            "13913/13913 [==============================] - 6s 432us/step - loss: 0.2493 - acc: 0.8980 - val_loss: 0.3796 - val_acc: 0.8836\n",
            "Epoch 18/50\n",
            "13913/13913 [==============================] - 6s 444us/step - loss: 0.2442 - acc: 0.9012 - val_loss: 0.3744 - val_acc: 0.8788\n",
            "Epoch 19/50\n",
            "13913/13913 [==============================] - 6s 433us/step - loss: 0.2274 - acc: 0.9079 - val_loss: 0.3683 - val_acc: 0.8825\n",
            "Epoch 20/50\n",
            "13913/13913 [==============================] - 6s 437us/step - loss: 0.2062 - acc: 0.9186 - val_loss: 0.3795 - val_acc: 0.8857\n",
            "Epoch 21/50\n",
            "13913/13913 [==============================] - 6s 449us/step - loss: 0.2048 - acc: 0.9204 - val_loss: 0.3861 - val_acc: 0.8864\n",
            "Epoch 22/50\n",
            "13913/13913 [==============================] - 6s 461us/step - loss: 0.1904 - acc: 0.9270 - val_loss: 0.3856 - val_acc: 0.8887\n",
            "Epoch 23/50\n",
            "13913/13913 [==============================] - 6s 452us/step - loss: 0.1767 - acc: 0.9319 - val_loss: 0.3957 - val_acc: 0.8857\n",
            "Epoch 24/50\n",
            "13913/13913 [==============================] - 7s 469us/step - loss: 0.1763 - acc: 0.9353 - val_loss: 0.4065 - val_acc: 0.8875\n",
            "Epoch 25/50\n",
            "13913/13913 [==============================] - 7s 471us/step - loss: 0.1780 - acc: 0.9320 - val_loss: 0.4018 - val_acc: 0.8898\n",
            "Epoch 26/50\n",
            "13913/13913 [==============================] - 6s 431us/step - loss: 0.1636 - acc: 0.9373 - val_loss: 0.4015 - val_acc: 0.8898\n",
            "Epoch 27/50\n",
            "13913/13913 [==============================] - 6s 460us/step - loss: 0.1619 - acc: 0.9388 - val_loss: 0.4029 - val_acc: 0.8918\n",
            "Epoch 28/50\n",
            "13913/13913 [==============================] - 7s 491us/step - loss: 0.1584 - acc: 0.9407 - val_loss: 0.4127 - val_acc: 0.8881\n",
            "Epoch 29/50\n",
            "13913/13913 [==============================] - 6s 457us/step - loss: 0.1479 - acc: 0.9430 - val_loss: 0.4140 - val_acc: 0.8922\n",
            "Epoch 30/50\n",
            "13913/13913 [==============================] - 7s 480us/step - loss: 0.1476 - acc: 0.9459 - val_loss: 0.4470 - val_acc: 0.8892\n",
            "Epoch 31/50\n",
            "13913/13913 [==============================] - 7s 482us/step - loss: 0.1390 - acc: 0.9488 - val_loss: 0.4360 - val_acc: 0.8922\n",
            "Epoch 32/50\n",
            "13913/13913 [==============================] - 9s 673us/step - loss: 0.1454 - acc: 0.9490 - val_loss: 0.4505 - val_acc: 0.8939\n",
            "Epoch 33/50\n",
            "13913/13913 [==============================] - 8s 571us/step - loss: 0.1328 - acc: 0.9527 - val_loss: 0.4358 - val_acc: 0.8952\n",
            "Epoch 34/50\n",
            "13913/13913 [==============================] - 9s 614us/step - loss: 0.1389 - acc: 0.9487 - val_loss: 0.4559 - val_acc: 0.8900\n",
            "Epoch 35/50\n",
            "13913/13913 [==============================] - 6s 461us/step - loss: 0.1331 - acc: 0.9529 - val_loss: 0.4346 - val_acc: 0.8922\n",
            "Epoch 36/50\n",
            "13913/13913 [==============================] - 7s 530us/step - loss: 0.1274 - acc: 0.9538 - val_loss: 0.4684 - val_acc: 0.8922\n",
            "Epoch 37/50\n",
            "13913/13913 [==============================] - 61s 4ms/step - loss: 0.1294 - acc: 0.9534 - val_loss: 0.4734 - val_acc: 0.8905\n",
            "Epoch 38/50\n",
            "13913/13913 [==============================] - 5s 334us/step - loss: 0.1324 - acc: 0.9534 - val_loss: 0.4605 - val_acc: 0.8969\n",
            "Epoch 39/50\n",
            "13913/13913 [==============================] - 5s 348us/step - loss: 0.1201 - acc: 0.9584 - val_loss: 0.4900 - val_acc: 0.8965\n",
            "Epoch 40/50\n",
            "13913/13913 [==============================] - 5s 360us/step - loss: 0.1203 - acc: 0.9583 - val_loss: 0.4738 - val_acc: 0.8984\n",
            "Epoch 41/50\n",
            "13913/13913 [==============================] - 5s 351us/step - loss: 0.1130 - acc: 0.9598 - val_loss: 0.4952 - val_acc: 0.8959\n",
            "Epoch 42/50\n",
            "13913/13913 [==============================] - 5s 351us/step - loss: 0.1240 - acc: 0.9549 - val_loss: 0.5064 - val_acc: 0.8950\n",
            "Epoch 43/50\n",
            "13913/13913 [==============================] - 5s 360us/step - loss: 0.1177 - acc: 0.9602 - val_loss: 0.4945 - val_acc: 0.8993\n",
            "Epoch 44/50\n",
            "13913/13913 [==============================] - 5s 334us/step - loss: 0.1181 - acc: 0.9569 - val_loss: 0.5168 - val_acc: 0.8965\n",
            "Epoch 45/50\n",
            "13913/13913 [==============================] - 5s 346us/step - loss: 0.1112 - acc: 0.9624 - val_loss: 0.4857 - val_acc: 0.8989\n",
            "Epoch 46/50\n",
            "13913/13913 [==============================] - 5s 352us/step - loss: 0.1140 - acc: 0.9617 - val_loss: 0.4773 - val_acc: 0.9023\n",
            "Epoch 47/50\n",
            "13913/13913 [==============================] - 5s 345us/step - loss: 0.1157 - acc: 0.9586 - val_loss: 0.4912 - val_acc: 0.8948\n",
            "Epoch 48/50\n",
            "13913/13913 [==============================] - 5s 342us/step - loss: 0.1140 - acc: 0.9597 - val_loss: 0.4999 - val_acc: 0.8961\n",
            "Epoch 49/50\n",
            "13913/13913 [==============================] - 5s 369us/step - loss: 0.1034 - acc: 0.9636 - val_loss: 0.5507 - val_acc: 0.8905\n",
            "Epoch 50/50\n",
            "13913/13913 [==============================] - 5s 328us/step - loss: 0.1034 - acc: 0.9643 - val_loss: 0.5424 - val_acc: 0.8935\n",
            "Train on 13913 samples, validate on 4638 samples\n",
            "Epoch 1/50\n",
            "13913/13913 [==============================] - 5s 361us/step - loss: 1.1047 - acc: 0.3922 - val_loss: 0.9904 - val_acc: 0.4612\n",
            "Epoch 2/50\n",
            "13913/13913 [==============================] - 5s 362us/step - loss: 0.9830 - acc: 0.4702 - val_loss: 0.9114 - val_acc: 0.5858\n",
            "Epoch 3/50\n",
            "13913/13913 [==============================] - 5s 338us/step - loss: 0.9037 - acc: 0.5401 - val_loss: 0.8467 - val_acc: 0.6016\n",
            "Epoch 4/50\n",
            "13913/13913 [==============================] - 5s 347us/step - loss: 0.8298 - acc: 0.5698 - val_loss: 0.7769 - val_acc: 0.6429\n",
            "Epoch 5/50\n",
            "13913/13913 [==============================] - 5s 346us/step - loss: 0.7650 - acc: 0.6067 - val_loss: 0.7050 - val_acc: 0.7160\n",
            "Epoch 6/50\n",
            "13913/13913 [==============================] - 5s 342us/step - loss: 0.6986 - acc: 0.6472 - val_loss: 0.6593 - val_acc: 0.7335\n",
            "Epoch 7/50\n",
            "13913/13913 [==============================] - 5s 330us/step - loss: 0.6413 - acc: 0.6734 - val_loss: 0.6236 - val_acc: 0.7178\n",
            "Epoch 8/50\n",
            "13913/13913 [==============================] - 5s 336us/step - loss: 0.5956 - acc: 0.6991 - val_loss: 0.5658 - val_acc: 0.7723\n",
            "Epoch 9/50\n",
            "13913/13913 [==============================] - 5s 343us/step - loss: 0.5566 - acc: 0.7180 - val_loss: 0.5332 - val_acc: 0.7889\n",
            "Epoch 10/50\n",
            "13913/13913 [==============================] - 5s 359us/step - loss: 0.5180 - acc: 0.7425 - val_loss: 0.5256 - val_acc: 0.7788\n",
            "Epoch 11/50\n",
            "13913/13913 [==============================] - 5s 349us/step - loss: 0.4779 - acc: 0.7687 - val_loss: 0.5132 - val_acc: 0.7846\n",
            "Epoch 12/50\n",
            "13913/13913 [==============================] - 5s 336us/step - loss: 0.4469 - acc: 0.7844 - val_loss: 0.4466 - val_acc: 0.8260\n",
            "Epoch 13/50\n",
            "13913/13913 [==============================] - 5s 348us/step - loss: 0.4106 - acc: 0.8107 - val_loss: 0.4470 - val_acc: 0.8310\n",
            "Epoch 14/50\n",
            "13913/13913 [==============================] - 5s 345us/step - loss: 0.3787 - acc: 0.8268 - val_loss: 0.4247 - val_acc: 0.8329\n",
            "Epoch 15/50\n",
            "13913/13913 [==============================] - 5s 345us/step - loss: 0.3440 - acc: 0.8450 - val_loss: 0.4048 - val_acc: 0.8538\n",
            "Epoch 16/50\n",
            "13913/13913 [==============================] - 5s 353us/step - loss: 0.3382 - acc: 0.8420 - val_loss: 0.3993 - val_acc: 0.8545\n",
            "Epoch 17/50\n",
            "13913/13913 [==============================] - 5s 333us/step - loss: 0.3126 - acc: 0.8616 - val_loss: 0.4046 - val_acc: 0.8579\n",
            "Epoch 18/50\n",
            "13913/13913 [==============================] - 5s 338us/step - loss: 0.2975 - acc: 0.8688 - val_loss: 0.3885 - val_acc: 0.8683\n",
            "Epoch 19/50\n",
            "13913/13913 [==============================] - 5s 346us/step - loss: 0.2851 - acc: 0.8749 - val_loss: 0.3903 - val_acc: 0.8687\n",
            "Epoch 20/50\n",
            "13913/13913 [==============================] - 5s 330us/step - loss: 0.2686 - acc: 0.8825 - val_loss: 0.3981 - val_acc: 0.8691\n",
            "Epoch 21/50\n",
            "13913/13913 [==============================] - 5s 331us/step - loss: 0.2525 - acc: 0.8932 - val_loss: 0.4022 - val_acc: 0.8728\n",
            "Epoch 22/50\n",
            "13913/13913 [==============================] - 5s 335us/step - loss: 0.2412 - acc: 0.8968 - val_loss: 0.4052 - val_acc: 0.8693\n",
            "Epoch 23/50\n",
            "13913/13913 [==============================] - 5s 337us/step - loss: 0.2335 - acc: 0.9017 - val_loss: 0.3916 - val_acc: 0.8762\n",
            "Epoch 24/50\n",
            "13913/13913 [==============================] - 5s 343us/step - loss: 0.2322 - acc: 0.9020 - val_loss: 0.4004 - val_acc: 0.8743\n",
            "Epoch 25/50\n",
            "13913/13913 [==============================] - 5s 329us/step - loss: 0.2123 - acc: 0.9125 - val_loss: 0.4144 - val_acc: 0.8739\n",
            "Epoch 26/50\n",
            "13913/13913 [==============================] - 5s 340us/step - loss: 0.2088 - acc: 0.9149 - val_loss: 0.4200 - val_acc: 0.8782\n",
            "Epoch 27/50\n",
            "13913/13913 [==============================] - 5s 326us/step - loss: 0.1942 - acc: 0.9207 - val_loss: 0.4305 - val_acc: 0.8769\n",
            "Epoch 28/50\n",
            "13913/13913 [==============================] - 4s 323us/step - loss: 0.1959 - acc: 0.9212 - val_loss: 0.4311 - val_acc: 0.8765\n",
            "Epoch 29/50\n",
            "13913/13913 [==============================] - 4s 318us/step - loss: 0.1919 - acc: 0.9215 - val_loss: 0.4325 - val_acc: 0.8765\n",
            "Epoch 30/50\n",
            "13913/13913 [==============================] - 5s 336us/step - loss: 0.1948 - acc: 0.9201 - val_loss: 0.4406 - val_acc: 0.8836\n",
            "Epoch 31/50\n",
            "13913/13913 [==============================] - 5s 342us/step - loss: 0.1804 - acc: 0.9267 - val_loss: 0.4191 - val_acc: 0.8842\n",
            "Epoch 32/50\n",
            "13913/13913 [==============================] - 5s 341us/step - loss: 0.1768 - acc: 0.9279 - val_loss: 0.4657 - val_acc: 0.8793\n",
            "Epoch 33/50\n",
            "13913/13913 [==============================] - 5s 331us/step - loss: 0.1725 - acc: 0.9322 - val_loss: 0.4643 - val_acc: 0.8862\n",
            "Epoch 34/50\n",
            "13913/13913 [==============================] - 5s 340us/step - loss: 0.1647 - acc: 0.9355 - val_loss: 0.4412 - val_acc: 0.8883\n",
            "Epoch 35/50\n",
            "13913/13913 [==============================] - 5s 341us/step - loss: 0.1632 - acc: 0.9367 - val_loss: 0.4475 - val_acc: 0.8866\n",
            "Epoch 36/50\n",
            "13913/13913 [==============================] - 4s 322us/step - loss: 0.1605 - acc: 0.9357 - val_loss: 0.4805 - val_acc: 0.8821\n",
            "Epoch 37/50\n",
            "13913/13913 [==============================] - 5s 344us/step - loss: 0.1583 - acc: 0.9378 - val_loss: 0.5280 - val_acc: 0.8810\n",
            "Epoch 38/50\n",
            "13913/13913 [==============================] - 5s 337us/step - loss: 0.1636 - acc: 0.9378 - val_loss: 0.4536 - val_acc: 0.8894\n",
            "Epoch 39/50\n",
            "13913/13913 [==============================] - 4s 319us/step - loss: 0.1492 - acc: 0.9415 - val_loss: 0.4943 - val_acc: 0.8773\n",
            "Epoch 40/50\n",
            "13913/13913 [==============================] - 5s 326us/step - loss: 0.1520 - acc: 0.9423 - val_loss: 0.4745 - val_acc: 0.8879\n",
            "Epoch 41/50\n",
            "13913/13913 [==============================] - 5s 341us/step - loss: 0.1455 - acc: 0.9437 - val_loss: 0.5120 - val_acc: 0.8864\n",
            "Epoch 42/50\n",
            "13913/13913 [==============================] - 5s 332us/step - loss: 0.1466 - acc: 0.9435 - val_loss: 0.4671 - val_acc: 0.8885\n",
            "Epoch 43/50\n",
            "13913/13913 [==============================] - 5s 336us/step - loss: 0.1396 - acc: 0.9463 - val_loss: 0.5033 - val_acc: 0.8829\n",
            "Epoch 44/50\n",
            "13913/13913 [==============================] - 4s 307us/step - loss: 0.1306 - acc: 0.9516 - val_loss: 0.5211 - val_acc: 0.8875\n",
            "Epoch 45/50\n",
            "13913/13913 [==============================] - 4s 309us/step - loss: 0.1333 - acc: 0.9498 - val_loss: 0.4891 - val_acc: 0.8868\n",
            "Epoch 46/50\n",
            "13913/13913 [==============================] - 4s 315us/step - loss: 0.1311 - acc: 0.9510 - val_loss: 0.5112 - val_acc: 0.8911\n",
            "Epoch 47/50\n",
            "13913/13913 [==============================] - 5s 330us/step - loss: 0.1279 - acc: 0.9497 - val_loss: 0.5058 - val_acc: 0.8918\n",
            "Epoch 48/50\n",
            "13913/13913 [==============================] - 4s 317us/step - loss: 0.1246 - acc: 0.9544 - val_loss: 0.4843 - val_acc: 0.8941\n",
            "Epoch 49/50\n",
            "13913/13913 [==============================] - 5s 330us/step - loss: 0.1228 - acc: 0.9531 - val_loss: 0.5197 - val_acc: 0.8898\n",
            "Epoch 50/50\n",
            "13913/13913 [==============================] - 5s 328us/step - loss: 0.1319 - acc: 0.9502 - val_loss: 0.5357 - val_acc: 0.8922\n",
            "Train on 13913 samples, validate on 4638 samples\n",
            "Epoch 1/50\n",
            "13913/13913 [==============================] - 5s 351us/step - loss: 1.1267 - acc: 0.3894 - val_loss: 0.9771 - val_acc: 0.5699\n",
            "Epoch 2/50\n",
            "13913/13913 [==============================] - 4s 322us/step - loss: 0.9815 - acc: 0.5521 - val_loss: 0.8843 - val_acc: 0.6576\n",
            "Epoch 3/50\n",
            "13913/13913 [==============================] - 4s 323us/step - loss: 0.9015 - acc: 0.6156 - val_loss: 0.7744 - val_acc: 0.7296\n",
            "Epoch 4/50\n",
            "13913/13913 [==============================] - 5s 330us/step - loss: 0.8159 - acc: 0.6503 - val_loss: 0.7239 - val_acc: 0.7313\n",
            "Epoch 5/50\n",
            "13913/13913 [==============================] - 5s 325us/step - loss: 0.7473 - acc: 0.6705 - val_loss: 0.6691 - val_acc: 0.7503\n",
            "Epoch 6/50\n",
            "13913/13913 [==============================] - 4s 317us/step - loss: 0.6818 - acc: 0.6947 - val_loss: 0.6296 - val_acc: 0.7674\n",
            "Epoch 7/50\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "13913/13913 [==============================] - 4s 319us/step - loss: 0.6292 - acc: 0.7091 - val_loss: 0.5735 - val_acc: 0.7863\n",
            "Epoch 8/50\n",
            "13913/13913 [==============================] - 5s 332us/step - loss: 0.5704 - acc: 0.7393 - val_loss: 0.5409 - val_acc: 0.7971\n",
            "Epoch 9/50\n",
            "13913/13913 [==============================] - 5s 328us/step - loss: 0.5403 - acc: 0.7551 - val_loss: 0.5088 - val_acc: 0.8144\n",
            "Epoch 10/50\n",
            "13913/13913 [==============================] - 5s 325us/step - loss: 0.4865 - acc: 0.7797 - val_loss: 0.4875 - val_acc: 0.8226\n",
            "Epoch 11/50\n",
            "13913/13913 [==============================] - 4s 308us/step - loss: 0.4547 - acc: 0.7970 - val_loss: 0.4633 - val_acc: 0.8301\n",
            "Epoch 12/50\n",
            "13913/13913 [==============================] - 4s 313us/step - loss: 0.4129 - acc: 0.8138 - val_loss: 0.4390 - val_acc: 0.8473\n",
            "Epoch 13/50\n",
            "13913/13913 [==============================] - 4s 307us/step - loss: 0.3889 - acc: 0.8240 - val_loss: 0.4172 - val_acc: 0.8583\n",
            "Epoch 14/50\n",
            "13913/13913 [==============================] - 4s 305us/step - loss: 0.3668 - acc: 0.8384 - val_loss: 0.4116 - val_acc: 0.8648\n",
            "Epoch 15/50\n",
            "13913/13913 [==============================] - 4s 317us/step - loss: 0.3407 - acc: 0.8441 - val_loss: 0.3985 - val_acc: 0.8670\n",
            "Epoch 16/50\n",
            "13913/13913 [==============================] - 5s 325us/step - loss: 0.3270 - acc: 0.8522 - val_loss: 0.3969 - val_acc: 0.8717\n",
            "Epoch 17/50\n",
            "13913/13913 [==============================] - 4s 321us/step - loss: 0.3029 - acc: 0.8654 - val_loss: 0.3934 - val_acc: 0.8724\n",
            "Epoch 18/50\n",
            "13913/13913 [==============================] - 5s 324us/step - loss: 0.2847 - acc: 0.8739 - val_loss: 0.3832 - val_acc: 0.8795\n",
            "Epoch 19/50\n",
            "13913/13913 [==============================] - 4s 320us/step - loss: 0.2693 - acc: 0.8807 - val_loss: 0.3812 - val_acc: 0.8801\n",
            "Epoch 20/50\n",
            "13913/13913 [==============================] - 4s 320us/step - loss: 0.2607 - acc: 0.8841 - val_loss: 0.3873 - val_acc: 0.8808\n",
            "Epoch 21/50\n",
            "13913/13913 [==============================] - 5s 328us/step - loss: 0.2591 - acc: 0.8874 - val_loss: 0.3838 - val_acc: 0.8844\n",
            "Epoch 22/50\n",
            "13913/13913 [==============================] - 4s 320us/step - loss: 0.2373 - acc: 0.8951 - val_loss: 0.3738 - val_acc: 0.8896\n",
            "Epoch 23/50\n",
            "13913/13913 [==============================] - 4s 318us/step - loss: 0.2245 - acc: 0.9058 - val_loss: 0.3778 - val_acc: 0.8890\n",
            "Epoch 24/50\n",
            "13913/13913 [==============================] - 4s 319us/step - loss: 0.2148 - acc: 0.9048 - val_loss: 0.3795 - val_acc: 0.8872\n",
            "Epoch 25/50\n",
            "13913/13913 [==============================] - 4s 308us/step - loss: 0.2091 - acc: 0.9121 - val_loss: 0.4034 - val_acc: 0.8868\n",
            "Epoch 26/50\n",
            "13913/13913 [==============================] - 5s 325us/step - loss: 0.2016 - acc: 0.9178 - val_loss: 0.4166 - val_acc: 0.8872\n",
            "Epoch 27/50\n",
            "13913/13913 [==============================] - 5s 324us/step - loss: 0.1978 - acc: 0.9188 - val_loss: 0.3963 - val_acc: 0.8952\n",
            "Epoch 28/50\n",
            "13913/13913 [==============================] - 4s 315us/step - loss: 0.1868 - acc: 0.9249 - val_loss: 0.4235 - val_acc: 0.8890\n",
            "Epoch 29/50\n",
            "13913/13913 [==============================] - 5s 335us/step - loss: 0.1853 - acc: 0.9240 - val_loss: 0.4201 - val_acc: 0.8881\n",
            "Epoch 30/50\n",
            "13913/13913 [==============================] - 5s 331us/step - loss: 0.1714 - acc: 0.9295 - val_loss: 0.4230 - val_acc: 0.8898\n",
            "Epoch 31/50\n",
            "13913/13913 [==============================] - 5s 325us/step - loss: 0.1769 - acc: 0.9255 - val_loss: 0.4186 - val_acc: 0.8928\n",
            "Epoch 32/50\n",
            "13913/13913 [==============================] - 5s 324us/step - loss: 0.1679 - acc: 0.9325 - val_loss: 0.4159 - val_acc: 0.8928\n",
            "Epoch 33/50\n",
            "13913/13913 [==============================] - 4s 309us/step - loss: 0.1705 - acc: 0.9310 - val_loss: 0.4281 - val_acc: 0.8941\n",
            "Epoch 34/50\n",
            "13913/13913 [==============================] - 4s 308us/step - loss: 0.1600 - acc: 0.9383 - val_loss: 0.4238 - val_acc: 0.8950\n",
            "Epoch 35/50\n",
            "13913/13913 [==============================] - 4s 319us/step - loss: 0.1565 - acc: 0.9376 - val_loss: 0.4405 - val_acc: 0.8926\n",
            "Epoch 36/50\n",
            "13913/13913 [==============================] - 5s 324us/step - loss: 0.1512 - acc: 0.9393 - val_loss: 0.4575 - val_acc: 0.8918\n",
            "Epoch 37/50\n",
            "13913/13913 [==============================] - 5s 336us/step - loss: 0.1548 - acc: 0.9393 - val_loss: 0.4466 - val_acc: 0.8946\n",
            "Epoch 38/50\n",
            "13913/13913 [==============================] - 5s 324us/step - loss: 0.1491 - acc: 0.9413 - val_loss: 0.4600 - val_acc: 0.8924\n",
            "Epoch 39/50\n",
            "13913/13913 [==============================] - 5s 330us/step - loss: 0.1481 - acc: 0.9415 - val_loss: 0.4584 - val_acc: 0.8915\n",
            "Epoch 40/50\n",
            "13913/13913 [==============================] - 5s 332us/step - loss: 0.1432 - acc: 0.9435 - val_loss: 0.4849 - val_acc: 0.8909\n",
            "Epoch 41/50\n",
            "13913/13913 [==============================] - 4s 320us/step - loss: 0.1516 - acc: 0.9419 - val_loss: 0.4469 - val_acc: 0.8920\n",
            "Epoch 42/50\n",
            "13913/13913 [==============================] - 5s 324us/step - loss: 0.1472 - acc: 0.9413 - val_loss: 0.4790 - val_acc: 0.8918\n",
            "Epoch 43/50\n",
            "13913/13913 [==============================] - 5s 325us/step - loss: 0.1380 - acc: 0.9453 - val_loss: 0.4672 - val_acc: 0.8944\n",
            "Epoch 44/50\n",
            "13913/13913 [==============================] - 5s 324us/step - loss: 0.1387 - acc: 0.9486 - val_loss: 0.4660 - val_acc: 0.8950\n",
            "Epoch 45/50\n",
            "13913/13913 [==============================] - 4s 312us/step - loss: 0.1351 - acc: 0.9476 - val_loss: 0.4817 - val_acc: 0.8961\n",
            "Epoch 46/50\n",
            "13913/13913 [==============================] - 4s 311us/step - loss: 0.1310 - acc: 0.9483 - val_loss: 0.4875 - val_acc: 0.8961\n",
            "Epoch 47/50\n",
            "13913/13913 [==============================] - 4s 313us/step - loss: 0.1282 - acc: 0.9518 - val_loss: 0.4989 - val_acc: 0.8931\n",
            "Epoch 48/50\n",
            "13913/13913 [==============================] - 4s 319us/step - loss: 0.1288 - acc: 0.9490 - val_loss: 0.5123 - val_acc: 0.8903\n",
            "Epoch 49/50\n",
            "13913/13913 [==============================] - 4s 316us/step - loss: 0.1339 - acc: 0.9494 - val_loss: 0.5116 - val_acc: 0.8909\n",
            "Epoch 50/50\n",
            "13913/13913 [==============================] - 4s 317us/step - loss: 0.1290 - acc: 0.9528 - val_loss: 0.5120 - val_acc: 0.8920\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNXwzFaqUW5r",
        "outputId": "89cf48cc-9606-43b2-f97c-1af00fff0120"
      },
      "source": [
        "# Plot Cross Validaton Results for Each Fold\n",
        "plt.figure()\n",
        "plt.plot(history.history['loss'],'b',label='Training Loss')\n",
        "plt.plot(history.history['val_loss'],'r',label='Validation Loss')\n",
        "plt.legend()\n",
        "    \n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(history.history['acc'],'b',label='Training Accuracy')\n",
        "plt.plot(history.history['val_acc'],'r',label='Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Accuracy')"
            ]
          },
          "execution_count": 225,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deZzN9f7A8dfbGAaDQcgalZTdNLSgaBGpdKVQivqlS+u9otxut33VptLeJW2kpFx1aRNSXVuLLZHIIGv2JWPevz/eZ8wY58yMmTnnzMx5Px+P7+Oc8z2f853315jv+3w/q6gqzjnnYlepaAfgnHMuujwROOdcjPNE4JxzMc4TgXPOxThPBM45F+NKRzuAI3XUUUdpgwYNoh2Gc84VK/PmzdukqtWDvVfsEkGDBg2YO3dutMNwzrliRURWhXrPq4accy7GeSJwzrkY54nAOediXLFrI3DORcb+/ftJTU1l79690Q7FHYGEhATq1q1LfHx8nj/jicA5F1RqaioVK1akQYMGiEi0w3F5oKps3ryZ1NRUGjZsmOfPedWQcy6ovXv3Uq1aNU8CxYiIUK1atSO+i/NE4JwLyZNA8ZOf31nMJIJFi2DIENizJ9qROOdc0RIziWDlSnjiCfj222hH4pzLzebNm2nVqhWtWrXi6KOPpk6dOgdf//nnn3k6xtVXX83SpUtzLPPcc8/x1ltvFUbItG/fnu+//75QjhVpMdNY3K4diMD06dCpU7Sjcc7lpFq1agcvqvfccw+JiYkMGTLkkDKqiqpSqlTw77OjR4/O9efccMMNBQ+2BIiZO4KkJGjVyhKBc654Wr58Oc2aNWPgwIEkJyezbt06rrvuOlJSUmjatCn33XffwbIZ39DT0tJISkpi2LBhtGzZktNOO40NGzYAcOeddzJixIiD5YcNG0bbtm1p3LgxX3/9NQC7du3ikksuoWXLlvTp04eUlJQ8f/Pfs2cP/fr1o3nz5iQnJzNjxgwAFixYQJs2bWjVqhUtWrRgxYoV7Nixg65du9KyZUuaNWvGe++9V5j/dDmKmTsCgDPPhBdfhH37oGzZaEfjXPHxt79BYdd6tGoFgWvwEVm8eDGjR4/mxRdfBOCRRx6hatWqpKWl0alTJ3r27EmTJk0O+cy2bds488wzeeSRRxg8eDCjRo1i2LBhhx1bVZk9ezaTJk3ivvvuY8qUKTz77LMcffTRTJgwgR9++IHk5OQ8x/rMM89QpkwZFixYwKJFizj//PNZtmwZzz//PEOGDKFXr17s27cPVeXDDz+kQYMG/Pe//z0Yc6TEzB0BWCLYuxfmzIl2JM65/DruuONo06bNwddjx44lOTmZ5ORklixZwuLFiw/7TLly5ejatSsAJ598MitXrgx67B49ehxW5quvvqJ3794AtGzZkqZNm+Y51q+++oorr7wSgKZNm1K7dm2WL1/O6aefzgMPPMDw4cNZvXo1CQkJtGjRgilTpjBs2DBmzZpF5cqV8/xzCiqm7gg6dLDH6dOhffvoxuJccZKfb+7hUqFChYPPly1bxtNPP83s2bNJSkqib9++QfvQlylT5uDzuLg40tLSgh67bKCqIGsZVc13rKE+e+WVV3Laaafx0Ucfce655zJmzBjOOOMM5s6dy8cff8zQoUO54IILuOOOO/L9s49ETN0RVKsGzZt7O4FzJcX27dupWLEilSpVYt26dUydOrXQf0b79u0ZP348YHX7we44QjnjjDMO9kpasmQJ69at4/jjj2fFihUcf/zx3HLLLXTr1o0ff/yRNWvWkJiYyJVXXsngwYOZP39+oZ9LKDF1RwBWPTR6NOzfD0cwFYdzrghKTk6mSZMmNGvWjGOPPZZ27doV+s+46aabuOqqq2jRogXJyck0a9YsZLXNeeedd3COnw4dOjBq1Cj++te/0rx5c+Lj43n99dcpU6YMb7/9NmPHjiU+Pp7atWvzwAMP8PXXXzNs2DBKlSpFmTJlDraBRIIU5LYnGlJSUrQgC9O8+y5cdpmNJzjllEIMzLkSZsmSJZx00knRDiPq0tLSSEtLIyEhgWXLltG5c2eWLVtG6dJF93t0sN+diMxT1ZRg5YvumYTJGWfY4/Tpngicc7nbuXMnZ599NmlpaagqL730UpFOAvlRss4mD2rWhBNPtERw223RjsY5V9QlJSUxb968aIcRVjHVWJzhzDPhq6/gwIFoR+Kcc9EXs4lg+/bCHyDjnHPFUUwmgox2gsBob+eci2kxmQjq1IHjjvPxBM45BzGaCMCqh2bOhPT0aEfinMuuY8eOhw0OGzFiBNdff32On0tMTARg7dq19OzZM+Sxc+uCPmLECHbv3n3w9fnnn8/WrVvzEnqO7rnnHh5//PECH6ewxXQi2LIFFi6MdiTOuez69OnDuHHjDtk3btw4+vTpk6fP165du0Czd2ZPBB9//DFJSUn5Pl5RF9OJALx6yLmiqGfPnkyePJl9+/YBsHLlStauXUv79u0P9utPTk6mefPmfPjhh4d9fuXKlTRr1gywqaB79+5NixYt6NWrF3uyLFM4aNCgg1NY33333YDNGLp27Vo6depEp8DiJQ0aNGDTpk0APPnkkzRr1oxmzZodnMJ65cqVnHTSSQwYMICmTZvSuXPnQ35OboIdc9euXXTr1u3gtNTvvPMOAMOGDaNJkya0aNHisDUa8ivmxhFkOOYY26ZPh5tuinY0zhVxEZ6Hulq1arRt25YpU6bQvXt3xo0bR69evRAREhISmDhxIpUqVWLTpk2ceuqpXHTRRSHX6n3hhRcoX748P/74Iz/++OMh00g/+OCDVK1alQMHDnD22Wfz448/cvPNN/Pkk08ybdo0jjrqqEOONW/ePEaPHs3//vc/VJVTTjmFM888kypVqrBs2TLGjh3LK6+8wmWXXcaECRPo27dvrv8MoY65YsUKateuzUcffQTYtNRbtmxh4sSJ/PTTT4hIoVRXQQzfEYDdFcyYAcVslg3nYkLW6qGs1UKqyh133EGLFi0455xzWLNmDevXrw95nBkzZhy8ILdo0YIWLVocfG/8+PEkJyfTunVrFi1alOuEcl999RV/+ctfqFChAomJifTo0YOZM2cC0LBhQ1q1agXkPNV1Xo/ZvHlzPvvsM26//XZmzpxJ5cqVqVSpEgkJCVx77bW8//77lC9fPk8/Izcxe0cA1o309dfhp5/Ap1RxLgdRmIf64osvPjgL5549ew5+k3/rrbfYuHEj8+bNIz4+ngYNGgSdejqrYHcLv/76K48//jhz5syhSpUq9O/fP9fj5DQ3W9ksq13FxcXluWoo1DFPOOEE5s2bx8cff8w//vEPOnfuzF133cXs2bP5/PPPGTduHCNHjuSLL77I08/JSczfEYC3EzhXFCUmJtKxY0euueaaQxqJt23bRo0aNYiPj2fatGmsWrUqx+NknQp64cKF/Pjjj4BNYV2hQgUqV67M+vXrD64MBlCxYkV27NgR9FgffPABu3fvZteuXUycOJEOGQud5FOoY65du5by5cvTt29fhgwZwvz589m5cyfbtm3j/PPPZ8SIEXleMjM3MX1HcNxxULu2JYKBA6MdjXMuuz59+tCjR49DehBdccUVXHjhhaSkpNCqVStOPPHEHI8xaNAgrr76alq0aEGrVq1o27YtYKuNtW7dmqZNmx42hfV1111H165dqVWrFtOmTTu4Pzk5mf79+x88xrXXXkvr1q3zXA0E8MADDxxsEAZITU0NesypU6cydOhQSpUqRXx8PC+88AI7duyge/fu7N27F1XlqaeeyvPPzUnYpqEWkVHABcAGVW0W5H0BngbOB3YD/VU115UYCjoNdXaXXw5ffglr1kCItibnYpJPQ118Hek01OGsGnoN6JLD+12BRoHtOuCFMMYS0plnwrp18Msv0fjpzjkXfWFLBKo6A9iSQ5HuwOtqvgWSRKRWuOIJpWNHe5w8OdI/2TnnioZoNhbXAVZneZ0a2BdRjRtDu3bw9NMQYj1r52JWcVvB0OXvdxbNRBCsRj7oGYjIdSIyV0Tmbty4sdADGTIEVq6E998v9EM7V2wlJCSwefNmTwbFiKqyefNmEhISjuhzYV2zWEQaAJNDNBa/BHypqmMDr5cCHVV1XU7HLFBj8R9/QJUqh+1OT7dVyypXhtmzvdHYOYD9+/eTmpqaa996V7QkJCRQt25d4uPjD9lfVNcsngTcKCLjgFOAbbklgQJ55x3o3x8WL4aGDQ95q1QpuPVW60I6Y0bm+ALnYll8fDwNs/2tuJIpbFVDIjIW+AZoLCKpIvJ/IjJQRDJ67H8MrACWA68AOc8vW1Dt29valE8+GfTtq66C6tXhscfCGoVzzhU5Ya0aCocCVQ1dcw2MGwe//QbZJpMCuO8+uPtuWLQImjQpYKDOOVeERGscQdEzZAjs2QPPPRf07euvh4SEkDcNzjlXIsVWImjSBC68EJ59FrIsOpHhqKPg6qvhjTdskJlzzsWC2EoEALfdBps3w+jRQd8ePBj274eRIyMcl3PORUnsJYJ27eC00+CJJ4KOIDv+ePjLX+CFF2DnzijE55xzERZ7iUDE7gp+/RUmTAhaZMgQG3IwalSEY3POuSiIrV5DGdLTbSWaxESYOzfoCLL27W1G0mXLoHRMT9btnCsJvNdQdqVKwdChMH8+hFjdJ2Paiffei2xozjkXabGZCAD69oWjj4bhw4O+fdFF1l7w7LMRjss55yIsdhNBQgLccgt88gkEWe6tVCkYNAi+/hp++CEK8TnnXITEbiIAm1woMTHkvBL9+1u+eCEqS+Y451xkxHYiSEqC666zCemCrDlatSr07g1vvgnbt0c+POeci4TYTgQAf/sbqIbsKzpoEOzaZcnAOedKIk8E9epBp04wdqwlhGzatIHkZHj++aBvO+dcseeJAKBPH1i+HObNO+wtEbsrWLQIvvoqCrE551yYeSIA6NEDypSBt98O+nafPrZ6mTcaO+dKIk8EYMtXdu1qjcYHDhz2doUK0K+fDS5bvz4K8TnnXBh5Ishw+eWwdq2tVRnEwIE2K6nPP+ScK2k8EWS44AIbUzB2bNC3TzrJ2pRfeinoTYNzzhVbnggylC8PF19s9T9//hm0yKBBsGoV/Pe/EY7NOefCyBNBVn362PzTU6cGffvii216Im80ds6VJJ4Isjr3XKhWLWTvofh4GDDA7gh+/TXCsTnnXJh4IsgqPh4uvRQmTQq5PNmAATa24KWXIhybc86FiSeC7C6/3Ba2nzQp6Nv16lkV0YsvwqZNEY7NOefCwBNBdu3aQd26IXsPAdx/P+zYYY/OOVfceSLIrlQpm3J0yhTYvDlokSZN4Nprbf6hZcsiHJ9zzhUyTwTBXH45pKWFXNwe4N57oWxZ+Mc/IhiXc86FgSeCYFq1gsaNQ/YeAutGevvtlitmzYpgbM45V8g8EQQjYncFM2ZAamrIYoMHQ61acOutPkW1c6748kQQSp8+dnXP4a6gQgV44AH43//g3XcjGJtzzhUi0WL2VTYlJUXnzp0bmR/WqZMtRLBsmc1DHcSBA9C6ta1itnixtRs451xRIyLzVDUl2Ht+R5CTxx6DjRvhoYdCFomLg8cfhxUrrBeRc84VN2FNBCLSRUSWishyERkW5P3KIvIfEflBRBaJyNXhjOeIpaTYQgQjRtiVPoTOnW27/37YsiWC8TnnXCEIWyIQkTjgOaAr0AToIyJNshW7AVisqi2BjsATIlImXDHly0MPQenS1kUoB489Blu3woMPRigu55wrJOG8I2gLLFfVFar6JzAO6J6tjAIVRUSARGALkBbGmI5c7dqWBN57D2bODFmsRQvo3x9GjrT1bZxzrrgIZyKoA6zO8jo1sC+rkcBJwFpgAXCLqqZnP5CIXCcic0Vk7saNG8MVb2hDhti0E3//O6QfFt5Bd95p49CefjqCsTnnXAGFMxFIkH3ZuyidB3wP1AZaASNFpNJhH1J9WVVTVDWlevXqhR9pbsqXh4cfhnnz4M03QxY79ljo2dMmpNu+PYLxOedcAYQzEaQC9bK8rot988/qauB9NcuBX4ETwxhT/l1+ObRpY3NK7NoVstjQoZYEXn45grE551wBhDMRzAEaiUjDQANwbyD73M6/AWcDiEhNoDEQuntONJUqBU89ZQ0Aw4eHLJaSAmedZUVDrHjpnHNFStgSgaqmATcCU4ElwHhVXSQiA0VkYKDY/cDpIrIA+By4XVWL7iz/7dpBr17WRSiHqSduu83yRQ6Dkp1zrsjwkcVHatUqm5Dussvg9deDFlG1eevS0mDBAruZcM65aPKRxYXpmGPgppvgrbdg+fKgRUTsrmDxYlvf2DnnijJPBPkxeLCtb/zYYyGLXHYZ1K+fY3OCc84VCZ4I8qNWLbjmGnjtNVizJmiR+HgbdjBjBnz7bWTDc865I+GJIL+GDrWpR598MmSRa6+FKlVyvHFwzrmo80SQXw0b2poFL70Ucm3jxES4/nqYOBF+/jnC8TnnXB55IiiIYcNscNmzz4YsctNNUKZMjjcOzjkXVZ4ICqJpU+jeHZ55BnbsCFqkZk2bjO611+D33yManXPO5YkngoL6xz/gjz9ynFMioznh7rsjGJdzzuWRJ4KCOuUUm1PiiSdg796gRY47Dm64AV59FRYujHB8zjmXC08EheGOO2DdOhgzJmSRu+6CSpXs7sA554oSTwSF4ayzoG1bGz2WFnxdnapV4V//gilTYOrUCMfnnHM58ERQGESsrWDFChg/PmSxG26wNQuGDLE2A+ecKwo8ERSWiy6CJk1sAZsQq5iVLQuPPmrtBKNGRTg+55wLwRNBYSlVytoKFi60EWQhXHKJzWb9r3+F7HHqnHMR5YmgMPXubVNU3313yLsCEetgtH693R0451y0eSIoTHFxcM89sGgRvPtuyGKnnGI544knYPXqyIXnnHPBeCIobJdeam0F996bY4vwww/bAjb//GcEY3POuSA8ERS2jLuCJUvgnXdCFmvQAP72N3jjDYjmgmvOOedLVYZDerqtVblvn1UTlS4dtNi2bTbquE0bX8nMORdeBV6qUkSOE5GygecdReRmEUkqzCBLlFKl7K7g559h7NiQxSpXtjEFU6bAN99ELjznnMsqr1VDE4ADInI88G+gIfB22KIqCS6+2O4K7rsv5GhjgBtvhKOOsrzhnHPRkNdEkK6qacBfgBGq+negVvjCKgEy7gqWL4c33wxZLDHR5h/65BP4+uvIheeccxnymgj2i0gfoB8wObAvPjwhlSAXXQTJyXD//bB/f8hiN9wA1av7XYFzLjrymgiuBk4DHlTVX0WkIRD6a64zItaNdMUKeP31kMUqVIDbboNPP4VZsyIYn3POkY9eQyJSBainqj+GJ6ScFYteQ1mp2giyDRus8bhMmaDFdu2yCemaN4fPPotwjM65Eq8weg19KSKVRKQq8AMwWkR8Fd68EIEHHoBVq6zhOIQKFeD22+Hzz2HmzAjG55yLeXmtGqqsqtuBHsBoVT0ZOCd8YZUwnTvDNdfAQw/BjBkhiw0caGsc+5KWzrlIymsiKC0itYDLyGwsdkfi6afh+OOhb19b4ziI8uVh2DCYNg2mT49wfM65mJXXRHAfMBX4RVXniMixwLLwhVUCJSbCW2/ZkpYDB1rbQRB//SvUquV3Bc65yMlTIlDVd1W1haoOCrxeoaqXhDe0EqhNG+tKOn58yPWNy5Wzxc6mT7c7A+ecC7e8NhbXFZGJIrJBRNaLyAQRqZuHz3URkaUislxEhoUo01FEvheRRSJS8itEhg6FTp1sSPHy5UGLDBgAderAzTfDnj0Rjs85F3PyWjU0GpgE1AbqAP8J7AtJROKA54CuQBOgj4g0yVYmCXgeuEhVmwKXHlH0xVFcnI0pKFMGLr886ECzhAT4979tsbO//S0KMTrnYkpeE0F1VR2tqmmB7TWgei6faQssD1Qj/QmMA7pnK3M58L6q/gagqhuOIPbiq25dePVVmDMn5HDi886z7qQvv5zjbNbOOVdgeU0Em0Skr4jEBba+wOZcPlMHyLr+VmpgX1YnAFUC4xTmichVwQ4kIteJyFwRmbtx48Y8hlzE9egB115rK9SMGRO08fj+++G006yq6JdfohCjcy4m5DURXIN1Hf0dWAf0xKadyIkE2Zf9alcaOBnoBpwH/EtETjjsQ6ovq2qKqqZUr57bjUgxMmIEnH469O8PXbrYVBRZxMfbLNZxcba05Z9/RidM51zJltdeQ7+p6kWqWl1Va6jqxdjgspykAvWyvK4LrA1SZoqq7lLVTcAMoGUeYy/+KlSw7kHPPmsLEjRrBsOHH9JucMwx1l4wd66NMXDOucJWkKUqB+fy/hygkYg0FJEyQG+swTmrD4EOIlJaRMoDpwBLChBT8RMXZz2IFi+2Eci3327dTOfMOVikRw8r8tRTMNmH8znnCllBEkGwqp+DAusX3IgNRFsCjFfVRSIyUEQGBsosAaYAPwKzgVdVdWEBYiq+6taFDz6A99+3CepOPdVGIwc89pitc9OvH6SmRjFO51yJk+81i0XkN1WtX8jx5KrYzT6aH9u22VQUU6fCDz/ASScBNnlpcjKkpNhgM8kxFTvnXKZ8zz4qIjtEZHuQbQc2psCFQ+XK1jBQsaJ1GUpPB+CEE6x6aPp0eOONKMfonCsxckwEqlpRVSsF2SqqaulIBRmTatSAJ56wlWpeeeXg7v/7P1veYOhQ2Lo1ivE550qMgrQRuHDr1w/OOsuWL1trHa5KlYLnn4dNm+Bf/4pyfM65EsETQVEmAi+9ZAMIbr754O7kZBg0yBLCd99FMT7nXIngiaCoO/54uOsumDABPvzw4O7774dq1Wzh+0ATgnPO5YsnguJgyBBbzPiGG2D7dgCqVLEupd98A6+9Ft3wnHPFmyeC4iA+3hqM166Ff/7z4O4rr4R27WwM2pYtUYzPOVeseSIoLk45xYYXP/ccfPstkNlw/McfcOedUY7POVdwqjZ2KMRytuHiiaA4efBBW7GmSxe45BIYOZIWpRdz4w3Kiy/afETOuWJq3Tq46CKbQqBaNesVMngwTJoU9sSQ75HF0RITI4tz8sMPNmvpF1/Ab78BkF6jJpO2d+T7Wufzz8VXEJ8QF+UgnXNHZPx46wq4e7f1Cz9wAL78Er7+GvbutR6ErVrBTTfB1blN/BxcTiOLPREUV6rw668218QXX7Dnv9Mo98c6ltZoT6NZYyh1/LHRjtA599VX8Nln0L69LS5SocKh72/ebJ1A3nkH2ra1tUlOPDHz/X37YPZsSwpffgk9e1rCyAdPBLFAlQ97vkHH928iIf4AZZ55AvnrdT4hkXPRMn8+nHkm7Nxpr0uXtpmFO3a0/bt3w/XXWzK45x4bOFo6fBM25HuuIVeMiHDRe1fxeL+FzNh/GjJoIJx/PqxZE+3InCuaJk60haFefNEuyjnZvdsGd55yik34ldsX6JUroVs3qFoVfvoJ/vtf6wauav2+u3Sx+eVr1LAp5++4I6xJIFeqWqy2k08+WV1oBw6o9ul1QK9npO4vU041KUn1rbdU09OjHZpzRcfSpaqJibaBatWqqnfcobpmzaHl1q5V/ec/VatVs3JHH22PAweq7t8f/NibN6ueeKL97S1adPj7O3aoTp2qOmaM6t69hX9uIQBzNcR1NeoX9iPdPBHkbt8+1XPPVT2x1FLd3PhU+zVffbXq7t3RDs25/Nu3T/W111TPPlv1vvtUd+7M33H27FFt2dIu7qtXq86YoXrxxaoiqvHxqldeqfqf/6j262evRVS7d1edPt2+ad12m/1Ndemium3b4cdu3161TBkrX4R4IohB27erpqSoVii7X1f1u9N+1a1aqf7yS7RDc7Fo82b7dp0fO3aoPvmkat269v+4Xr3Mb+cvvRT6m3kogwbZ5z/66ND9y5er3nyzaoUK9n758qo33qi6bNnhx3jpJdW4ONXmzVV/+832HTig2rOnfXbcuPydaxh5IohRGzaonnCC3aEuf3qyPUlKUp08OdqhuVixb5/qY49ZFYyI6gUX2AU4LS33z27YoHrnnapVqtil6swzVT/+2Ko5Z81SbdfO9p94ouoHH+St+vOdd+wzQ4eGLvPHH3a8LVtyPtbUqaoVK6rWqqU6d67q3/9ux3788dzjiAJPBDFs5UrV+vXt+v/dhF/srgBU//WvvP0xOpdfn35qF2mwBHDHHao1a9rrBg1UH35Ydf16K5uWZvXpY8bYt/LTT1ctW9bKXnyx6jffHH789HTViRNVGze2cu3bWzVPKMuW2YX7tNNU//yzcM5xwQL7A4uPtxhuvrnItsd5IohxK1eqHnus/Q3M+my3tReAaufOmX+IzuVVerrqnDmqCxdaHWR2q1ZlVpEcd5zVt2fYt091/HjVTp3s/fj4QB1moDomo0qmfXvVwYNVlyzJPZ79+1VffDGzIff001UnTbKqmgx796omJ9vdxapVBf83yGrdOrtbueqqIv3lyhOB09RU++JUvrzq55+r6iuv2DeupCTVkSOPvJ7VxZ60NLuIt2yZedEG+z/UvLlqt252MSxfXrVcOdX777fG01CWLFG95Ra7iN50k90NLFqU/4vprl32f/mYYyyuJk3smH/+aXX9oPrhh/k7dgmQUyLwAWUxZP16OOccWL7culB3afCTDVn/7DNo2dImtGvXLtphuqImLQ3GjoWHHrI+8Y0bW5/4ihVtmpOs25o1Nljq8cfhmGOiE+/+/TZlwyOPwMKFUKuWzePz97/Dk09GJ6YiwEcWu4M2bYLOnWHRIvtb6X6Rwvvv2x/J6tU2t/Wjj9ofj4sNe/bYf4i0NFvlKD3d5rpJT4elS20A1IoVtibGnXfahIdxxWA+K1X4+GMYPhzKloXJk6FMmWhHFTU5JYKoV/Uc6eZVQwW3ZYtq27aqpUtb5whVtT7Z//yn9X+uWFH10Ud93EFRMHOm6r335r1e+6efbLDTU0/lXC2jmtnYWr/+oVU92bc2baxKJWuduyt28DYCl922bZYMypdXnT8/yxvLllldL1i/7X//29sPomH9ehvQlHExLltW9dZbVTdtCl5+40arBy9dOrMHS716qq++Gvz3t8oah/wAABOySURBVGyZateuVq5ZM9WxY61r5pQp1tvn889Vp02z/xxFtBeMOzKeCFxQ69bZtaJu3SBjfaZNs0wBqiedZN8c/YIQfmlpqs8/bw2w8fGqw4ZZo+rVV1s//MqVVR95JPNube9e1eHDbX+pUnY3sH696mefZf7+Gje2Rt4DB+xzd91liaViRRuoVVhdKV2R5onAhfT999Zzr02bIDVB6emqEyZk9tM+7TTVL788sh8QwblUir05c6wrJVj3ysWLD31/wQLrjw+qdeqo3n23asOG9vr88w+f1yaj6qdJEyuTnJxZ/vLLD59Xx5VoOSUCbyx2fPgh/OUvcOmlMG5ckJmr09Lgtddsqtw1a+Css+x5hw6hDzp7tvXa+OADm3b33ntzLl9SbNsGM2bAzJk2/bDI4du+fbBrl207d2Y+LlgANWvCE09Anz6hpxCfMcOmLP7f/6BFCyt/zjmhYzpwAN5+G+6/H8qVs4WNOnUKz/m7Ist7DblcDR8Ot98Od99t1/ig9uyxqXgfecT6op59thVu397eV4VPP7X3p02DKlUsu0yaBL//bgnk3nszy0dSerpdbLdtg+3boX596/5YULt32ypSX3wBn39u64Wmp1svlYoVgze/likDiYm2SEnGlpgITZvaL6Fy5dx/rqr1Az722OLRg8dFnScClytVuOYa++I/diz07p1D4Yy52R99NHNwQo8e8Mor8N13ULs23HorDBhgF8M9e2zO96zl77kn9zELqnbh3rTJFu/YswcqVbILZcYWH29lt2yBn3+2belSe1y+3D63bRvs2HHoHPJly9p6DZddBhdcYBfivNq/H6ZMgTfesCS3b5/NJX/KKZbszjoLTj0VEhLyfkznwswTgcuTffvg3HMzV8Y79dRcPrB7N7zwgt1ObNgAJ5xg32ivuMIutKHKP/oobNxoZRISDt/27bML+JYtVq2Rk3Ll7Bv2tm2Z++Li7Jtyo0a28Ef25FGhAnz7Lbz7rg00SkiwRUQuu8yqsapUyUwwGVTt2/4bb1im3LQJqleHXr0soXTocGTJxLkIi1oiEJEuwNNAHPCqqj4Solwb4Fugl6q+l9MxPRGE16ZN9sV23TobaNy/fx5Wu9y1CxYvhuTkvFVT7Npla7OuWmULc+/daxf/vXvtW398PBx1FFSrZlvG83LlrFpn27ZDt717oWFDS0SNG9vz7BfyYNLTYdYsG1n33ntWfZWhQgVISrKkkJRkie7nny15de9uA+/OOy9vP8e5IiAqiUBE4oCfgXOBVGAO0EdVFwcp9ymwFxjliSD6fv/dvtR/8YVd755/Pga+7B44YAuN//CDJZetWw/d4uNt4fCePS0xOFfM5JQIwrlIZltguaquCAQxDugOLM5W7iZgAtAmjLG4I3D00fDJJ/Dgg1aVP2eOfWlu3jzakYVRXJzNkXPmmdGOxLmIC+fi9XWA1Vlepwb2HSQidYC/AC/mdCARuU5E5orI3I0bNxZ6oO5wcXFw113WEWbrVmjbFl59Nfc1u51zxU84E0GwmuXsl5ERwO2qmmOLoKq+rKopqppSvXr1QgvQ5a5TJ/j+e+vxOWAA9Otn1fnOuZIjnIkgFaiX5XVdYG22MinAOBFZCfQEnheRi8MYk8uHmjWtt+Q991inmQsusN6YzrmSIZyJYA7QSEQaikgZoDcwKWsBVW2oqg1UtQHwHnC9qn4QxphcPsXF2WCz0aNtrNhZZ1kPUOdc8Re2RKCqacCNwFRgCTBeVReJyEARGRiun+vCq39/W9Rm4UKrLlq1KtoROecKygeUuXyZNcuqiMqXh6lToVmzaEfknMtJTt1Hw1k15Eqwdu1sXjWwQbWzZkU3Hudc/nkicPnWrJklgBo1bPog717qXPHkicAVSIMGNiC3QwfrXtq796HT/jjnij5PBK7Aqle37qUPPwwTJkDr1jZVvnOuePBE4ApFqVIwbJi1G6SnW4+i4cPtuXOuaPNE4ArVaafZSOTu3W1G6q5dYfp0m8LfOVc0eSJwhS4pyab6f/FFu0Po2NEalHv3hjfftKmunXNFhycCFxYi8Ne/2pTW771nayJ/+aVNa12jBpx+uk1o55yLPk8ELqwqVYJLLoFRo2DtWlv97K67bHqKbt3gs8+iHaFzzhOBi5hSpaBNG5u87ttvbTGxiy6CGTOiHZlzsc0TgYuKatXg009tVclu3eCbb6IdkXOxyxOBi5oaNaxqqFYt6NLF1oZ3zkWeJwIXVbVq2drI1apB587W9dQ5F1meCFzU1a1rySAxEc4915OBc5HmicAVCQ0aWDIoU8amqOjQAV5+Gf74I9qROVfyeSJwRcbxx8O8efDQQ7B5s41DOPpo6NED3n/f10p2Llx8YRpXJKnCd9/ZSOS334b1622QWuXKNnI561arFvz979CoUbSjdq7oymlhGk8ErshLS7NRyLNmwdatNs311q2Z2/LlVmbIELjjDqhQIdoRO1f0eCJwJdq6dXDbbXb3UK8ePPWUVSeJRDsy54oOX6rSlWi1asEbb9gI5aQk6NkTzjsPli6NdmTOFQ+eCFyJ0aEDzJ8PTz9tC+M0bw59+9o02MXsxte5iPJE4EqU0qXh5pvh55+t19HkyTYN9gknwKOP2myozrlDeRuBK9F277blM1991aqO4uLgggssOdSseehWtapNjOdcSeSNxc5hbQajRsGYMdYdNbu4OBvMdttt1tgcFxf5GJ0LF08EzmWhaiOW168/dPv9dxu4tnSpVSUNG2ZtDPHx0Y7YuYLzROBcHh04ABMn2ujm776D+vVh6FD4v/+DcuWiHZ1z+eeJwLkjpApTp8KDD8JXX1kSqFfPJsirUydzq1cPWrSwuZJ83IIrynJKBKUjHYxzxYGIrZHQpQvMnGl3CampsGaNdUddu9ZGM2eoUgWSk+HkkzO3Y4/15OCKB08EzuWiQwfbskpPt3WXV660abPnzbPtqadg/34r06wZDBhg7QxVq0Y8bOfyzKuGnCtEf/4JCxfa0ptjxsCcOVC2rI12HjAAzjjD7xJcdHgbgXNR8sMP8MorNg/Stm02Q2qXLnDMMYdu1at7gnDhFbVEICJdgKeBOOBVVX0k2/tXALcHXu4EBqnqDzkd0xOBK45274b33rNxDPPnw44dh75frpz1UGrY8PCtQQOrWvJE4QoiKolAROKAn4FzgVRgDtBHVRdnKXM6sERV/xCRrsA9qnpKTsf1ROCKO1WbPnvVKtt++80eV66EX3+FFSvs/azKloXatW2CvYzH+vWhXz+7m3AuN9HqNdQWWK6qKwJBjAO6AwcTgap+naX8t0DdMMbjXJEgYr2MqlSBVq2Cl9m61ZLCr79akli71qbbXrvW2iA++QS2b7furfffDwMH2jxLOUlPt0efRsNlF85EUAdYneV1KpDTt/3/A/4b7A0RuQ64DqB+/fqFFZ9zRVZSkk130bp16DJLlsBNN9n26qswciS0b39oGVXr1TRmjK30lpYG55xj7RSdO9u4iOzS0+GXX6x9Y9s26/VUtmzhnp8rWsKZCILVaAathxKRTlgiaB/sfVV9GXgZrGqosAJ0rjg76ST49FObVG/wYOvi2rcvDB9u77/1liWAhQuhTBm48EKoWNEGyr37rpVp2tTWbjjuOCv3/fewYAHs3Jn5c155xX5GnTqRP0cXGeFMBKlAvSyv6wJrsxcSkRbAq0BXVd0cxnicK3FErGtq167w8MPw2GM2X9LevfbN/tRT4fnnoVevzLEMqnbRnzrVtueeg337bD3oli3hmmvssWVLuzO45hpISbHG7nbtonu+LjzC2VhcGmssPhtYgzUWX66qi7KUqQ98AVyVrb0gJG8sdi60ZcvgkUfg6KPhqqugcePcP7N7N2zebNVEwXomLVoEF19sbRXPPGPrPHgPpuInKo3FqpomIjcCU7Huo6NUdZGIDAy8/yJwF1ANeF7sf1ZaqECdc7lr1Aj+/e8j+0z58raF0rQpzJ4NV1wBgwbZCOqRIw9tN1C1xus1a+Coo6BGjfzF76LDB5Q55/LkwAG46y6bmTUlxSbbW73a5mBavfrQdoW6dW3upYz5l5KTrcur30lEj08655wrsLg4666anGx3BqmpNvvqSSfBuefa8zp1rIvr/Pm2/ec/metFx8dbF9fSpQ99XrlyZsJISbGeUomJhRNzRq+pUqWszcMF53cEzrmw2bHDuqHOm2cL/6SlZW7799vjxo32/po19hkROPFEG2Nx9NFW1VStWuZ21FF2d1GtWvA7jB074LPP4KOP4OOPbfwFWHfZu+6K3QZvvyNwzkVFxYo2tiH7+IZg1q+3hDB3rj1+840liV27gpcvU8ZGWdepkznaevFimyZ8/36oVMku/t26wYYN8PjjFsfZZ1tCOOOMw4+5bp3dySxdagmnfv3MdShK8lgKvyNwzhVpe/dar6bNm2HTJtsyRlmvWWPb2rW21atnF/5u3eybf9ZlRnftgpdesnEW69dDx442Rccvv2RWZf3+e+g4ata0xNCunY3J6NCheC1j6rOPOudcwO7dNkju0UctocTFQZMmmY3brVtbu8cff9g8UKtX2+Nvv1nS+Pprm268cmUbv3HhhfZYpUq0zyxnngiccy6bPXts3EWjRke2HvXOndYG8Z//wOTJVu0UF2ftGhlVSfXrZz5PSLBkkpFQMh5377apPi69FNq2Df8cUJ4InHMuDNLTbfGhyZNttHbGhX7jxuDlExMzEwTAtGl2d1G3ro0Qv/RSGw0ejqTgicA55yJozx7rXvvbb/Y84+KflHRoT6dt22DSJJu+Y8oUSwo1a9p0IFkvzRnPBwyAW2/NX0zea8g55yKoXDmrcmrUKOdylSvDlVfatn273VlMmWIN5HBo0hCxnlHh4InAOeeKgEqV4PLLbYs0X6LCOedinCcC55yLcZ4InHMuxnkicM65GOeJwDnnYpwnAueci3GeCJxzLsZ5InDOuRhX7KaYEJGNwKp8fvwoYFMhhlOcxOq5+3nHFj/v0I5R1erB3ih2iaAgRGRuqLk2SrpYPXc/79ji550/XjXknHMxzhOBc87FuFhLBC9HO4AoitVz9/OOLX7e+RBTbQTOOecOF2t3BM4557LxROCcczEuZhKBiHQRkaUislxEhkU7nnARkVEiskFEFmbZV1VEPhWRZYHHKtGMMRxEpJ6ITBORJSKySERuCewv0ecuIgkiMltEfgic972B/SX6vDOISJyIfCcikwOvS/x5i8hKEVkgIt+LyNzAvgKdd0wkAhGJA54DugJNgD4i0iS6UYXNa0CXbPuGAZ+raiPg88DrkiYNuFVVTwJOBW4I/I5L+rnvA85S1ZZAK6CLiJxKyT/vDLcAS7K8jpXz7qSqrbKMHSjQecdEIgDaAstVdYWq/gmMA7pHOaawUNUZwJZsu7sDYwLPxwAXRzSoCFDVdao6P/B8B3ZxqEMJP3c1OwMv4wObUsLPG0BE6gLdgFez7C7x5x1Cgc47VhJBHWB1ltepgX2xoqaqrgO7YAI1ohxPWIlIA6A18D9i4NwD1SPfAxuAT1U1Js4bGAHcBqRn2RcL563AJyIyT0SuC+wr0HnHyuL1EmSf95stgUQkEZgA/E1Vt4sE+9WXLKp6AGglIknARBFpFu2Ywk1ELgA2qOo8EekY7XgirJ2qrhWRGsCnIvJTQQ8YK3cEqUC9LK/rAmujFEs0rBeRWgCBxw1RjicsRCQeSwJvqer7gd0xce4AqroV+BJrIyrp590OuEhEVmJVvWeJyJuU/PNGVdcGHjcAE7Gq7wKdd6wkgjlAIxFpKCJlgN7ApCjHFEmTgH6B5/2AD6MYS1iIffX/N7BEVZ/M8laJPncRqR64E0BEygHnAD9Rws9bVf+hqnVVtQH29/yFqvalhJ+3iFQQkYoZz4HOwEIKeN4xM7JYRM7H6hTjgFGq+mCUQwoLERkLdMSmpV0P3A18AIwH6gO/AZeqavYG5WJNRNoDM4EFZNYZ34G1E5TYcxeRFljjYBz2xW68qt4nItUoweedVaBqaIiqXlDSz1tEjsXuAsCq9t9W1QcLet4xkwicc84FFytVQ84550LwROCcczHOE4FzzsU4TwTOORfjPBE451yM80TgXICIHAjM6JixFdqEZSLSIOuMsM4VJbEyxYRzebFHVVtFOwjnIs3vCJzLRWD+90cD8/7PFpHjA/uPEZHPReTHwGP9wP6aIjIxsEbADyJyeuBQcSLySmDdgE8CI4ERkZtFZHHgOOOidJouhnkicC5TuWxVQ72yvLddVdsCI7ER6gSev66qLYC3gGcC+58BpgfWCEgGFgX2NwKeU9WmwFbgksD+YUDrwHEGhuvknAvFRxY7FyAiO1U1Mcj+ldjiLysCE9v9rqrVRGQTUEtV9wf2r1PVo0RkI1BXVfdlOUYDbIroRoHXtwPxqvqAiEwBdmJTgXyQZX0B5yLC7wicyxsN8TxUmWD2ZXl+gMw2um7YCnonA/NExNvuXER5InAub3plefwm8PxrbOZLgCuArwLPPwcGwcFFYyqFOqiIlALqqeo0bJGVJOCwuxLnwsm/eTiXqVxgpa8MU1Q1owtpWRH5H/blqU9g383AKBEZCmwErg7svwV4WUT+D/vmPwhYF+JnxgFvikhlbAGlpwLrCjgXMd5G4FwuAm0EKaq6KdqxOBcOXjXknHMxzu8InHMuxvkdgXPOxThPBM45F+M8ETjnXIzzROCcczHOE4FzzsW4/weKtCwvWROcOAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMC2vZDYU6Hc",
        "outputId": "0c7c50c4-3c48-4ede-d131-7f25ca389639"
      },
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "# Unpack Test Results\n",
        "precision = []; recall = []; f1 = [];\n",
        "for i in range(5):\n",
        "    metrics = np.array(precision_recall_fscore_support(np.array(y_all)[i,:], np.argmax(np.array(y_pred_all)[i,...],axis=1), beta=1.0, average=None))\n",
        "    precision.append(np.array(metrics)[0,:])\n",
        "    recall.append(np.array(metrics)[1,:])\n",
        "    f1.append(np.array(metrics)[2,:])\n",
        "\n",
        "print('Precision')\n",
        "print(str(np.mean(precision,axis=0)) + ' + ' + str(np.std(precision,axis=0)))\n",
        "print('Recall')\n",
        "print(str(np.mean(recall,axis=0)) + ' + ' + str(np.std(recall,axis=0)))\n",
        "print('F1')\n",
        "print(str(np.mean(f1,axis=0)) + ' + ' + str(np.std(f1,axis=0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision\n",
            "[0.89215047 0.82055711 0.92004593] + [0.00335422 0.02219356 0.00970015]\n",
            "Recall\n",
            "[0.94156928 0.62462006 0.93383838] + [0.01173671 0.01732789 0.01106798]\n",
            "F1\n",
            "[0.91614731 0.70907881 0.92681016] + [0.0051949  0.01494278 0.00573638]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ADi44bvTp_O"
      },
      "source": [
        "# Returns Compiled Model for Classifier 1 (Awake v Sleep)\n",
        "\n",
        "def Classifier(input_shape):\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=input_shape))\n",
        "    model.add(Dense(28,kernel_initializer='he_normal', bias_initializer='zeros')) # Kaiming He initialization\n",
        "    model.add(Activation('relu')) \n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(24,kernel_initializer='he_normal', bias_initializer='zeros')) # Kaiming He initialization\n",
        "    model.add(Activation('relu')) \n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(3))\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    adam = optimizers.Adam(lr=0.0005) # a smaller learning rate is better for Adam; otherwise, it's validation accuracy is highly inconsistent; good with batch_size=168\n",
        "    sgd = optimizers.SGD(lr=0.000001, momentum=0.9)\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "    return(model)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}